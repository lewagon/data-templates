{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step guide to Unit Tests used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T14:24:55.279012Z",
     "start_time": "2022-03-14T14:24:53.949004Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ts_boilerplate.params import ROOT_DIR, DATA, TRAIN, CROSS_VAL\n",
    "from ts_boilerplate.dataprep import get_X_y, get_folds, train_test_split, get_Xi_yi\n",
    "from ts_boilerplate.generate_dummy_data import generate_data_monotonic_increase, generate_data_zeros_and_ones, generate_X_y_zeros_and_ones\n",
    "from ts_boilerplate.model import get_model, fit_model, predict_output\n",
    "from ts_boilerplate.metrics import mape\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) `generate_dummy_data.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dummy time series dataset whose value increment by 1 every day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_data_monotonic_increase()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T14:25:19.973275Z",
     "start_time": "2022-03-14T14:25:19.950901Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store as CSV\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df.to_csv(os.path.join(ROOT_DIR, \"data\", \"dummy\", \"data_dummy.csv\"), index=False)\n",
    "pd.read_csv(os.path.join(ROOT_DIR, \"data\", \"dummy\", \"data_dummy.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) `dataprep.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) `getX_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_X_y(data, **TRAIN)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the shape arithmetically (for unittests)\n",
    "(len(data) \\\n",
    "            - (TRAIN['input_length']  -1) \\\n",
    "            - (TRAIN['output_length'] -1) \\\n",
    "            - TRAIN['horizon']) \\\n",
    "        / TRAIN[\"stride\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ ceiling rounding function should be used for stride > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = TRAIN[\"train_test_ratio\"]\n",
    "input_length = TRAIN[\"input_length\"]\n",
    "output_length = TRAIN[\"output_length\"]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_idx = round(train_test_ratio * len(data))\n",
    "data_train = data[0:last_train_idx, :]\n",
    "\n",
    "first_test_idx = last_train_idx - input_length\n",
    "data_test = data[first_test_idx:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y(data_train, **TRAIN)\n",
    "X_test, y_test = get_X_y(data_test, **TRAIN)\n",
    "\n",
    "print(\"####### Last train pair\")\n",
    "print(X_train[-1])\n",
    "print(y_train[-1])\n",
    "print(\"####### First test pair\")\n",
    "print(X_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = np.min(y_test) - np.max(y_train)\n",
    "gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert gap >= TRAIN[\"horizon\"], \"❗️❗️ Data leak detected between (X_train, y_train) and (X_test, y_test)❗️❗️ \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) `get_folds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = get_folds(data, **CROSS_VAL)\n",
    "print('n_folds= ', len(folds))\n",
    "print(folds[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) `model.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, **TRAIN)\n",
    "X_train, y_train = get_X_y(data_train, **TRAIN)\n",
    "X_test, y_test = get_X_y(data_test, **TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, SimpleRNN, Reshape, Lambda, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE: PREDICT LAST VALUE - ZERO TRAINABLE WEIGHTS\n",
    "input = Input(shape=X_train.shape[1:])\n",
    "# Take last temporal values of the targets, and duplicate it as many times as `output_length`\n",
    "x = Lambda(\n",
    "    lambda x: tf.repeat(tf.expand_dims(tf.gather(x[:, -1, :], indices=DATA['target_column_idx'], axis=1), axis=1),\n",
    "                        repeats=TRAIN['output_length'],\n",
    "                        axis=1))(input)\n",
    "output = Reshape(y_train.shape[1:])(x)\n",
    "model = Model(input, output)\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), metrics=tf.keras.metrics.MAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                        patience=2,\n",
    "                                        verbose=0,\n",
    "                                        mode='min',\n",
    "                                        restore_best_weights=True)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.3,\n",
    "                    callbacks=[es],\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts_boilerplate.metrics import mape\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mape(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) `main.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) `train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_data_monotonic_increase()\n",
    "data_train, data_test = train_test_split(data, **TRAIN)\n",
    "X_train, y_train = get_X_y(data_train, **TRAIN)\n",
    "X_test, y_test = get_X_y(data_test, **TRAIN)\n",
    "model = get_model(X_train, y_train)\n",
    "history = fit_model(model, X_train, y_train)\n",
    "y_pred = predict_output(model, X_test)\n",
    "metrics_test = mape(y_test, y_pred)\n",
    "\n",
    "print(\"### Test Metric: \", metrics_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) `backtesting()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_backtest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_data_monotonic_increase()\n",
    "from ts_boilerplate.model import get_model, fit_model, predict_output\n",
    "from ts_boilerplate.dataprep import get_Xi_yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 10\n",
    "start_ratio:float = 0.8\n",
    "retrain: bool = True\n",
    "retrain_every: int = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Initialization\n",
    "start_timestep_0 = round(start_ratio * len(data))\n",
    "data_train_0 = data[:start_timestep_0, ...]\n",
    "X_train_tmp, y_train_tmp = get_X_y(data_train_0, **TRAIN)\n",
    "data_test_backtested = data[start_timestep_0:, ...]\n",
    "_, y_test = get_X_y(data_test_backtested, **TRAIN, shuffle=False)\n",
    "y_pred_backtested = []\n",
    "retrain_counter = 0\n",
    "timesteps_backtested_list = []\n",
    "\n",
    "for i in tqdm(range(0, len(data_test_backtested), stride)):\n",
    "    start_timestep_i = start_timestep_0 + i\n",
    "    data_train = data[:start_timestep_i, ...]\n",
    "    data_test = data[start_timestep_i:, ...]\n",
    "    X_train_tmp, y_train_tmp = get_X_y(data_train, **TRAIN)\n",
    "    X_test_i, y_test_i = get_Xi_yi(first_index=0, data=data_test, **TRAIN)\n",
    "\n",
    "    # At some point after sliding through time, we will reach the end of the test set\n",
    "    if y_test_i.shape[0] < y_train_tmp.shape[1]:\n",
    "        break\n",
    "\n",
    "    model = get_model(X_train_tmp, y_train_tmp)\n",
    "\n",
    "    # Retrain when required, with incremental learning (ie. starting from previous weights)\n",
    "    if retrain and i % retrain_every == 0:\n",
    "        retrain_counter += 1\n",
    "        fit_model(model, X_train_tmp, y_train_tmp)\n",
    "\n",
    "    y_pred_i = np.squeeze(predict_output(model, X_test_i[None, ...]))\n",
    "    y_pred_backtested.append(y_pred_i)\n",
    "    timesteps_backtested_list.append(i)\n",
    "\n",
    "y_pred_backtested = np.array(y_pred_backtested)\n",
    "y_test_backtested = y_test[timesteps_backtested_list]\n",
    "# Check that we compare apples to apples\n",
    "assert y_pred_backtested.shape == y_test_backtested.shape\n",
    "\n",
    "metrics_backtested = mape(y_pred_backtested, y_test_backtested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'### BACKETESTED METRICS BASED ON THE LAST {y_pred_backtested.shape[0]} TIMESTEPS AND WITH {retrain_counter} retrain operations'\n",
    ")\n",
    "print(mape(y_pred_backtested, y_test_backtested))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make it work for any dimension of y\n",
    "plt.plot(y_pred_backtested[:,0,0], label='historical forecasts')\n",
    "plt.plot(y_test_backtested[:,0,0], label='truth')\n",
    "plt.xlabel('timesteps')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "572b4e543617d03e90ecaf525e08695da1ff29b13594f787e33b342cf572f792"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
