{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "We will go through the main issues you will face when working with Recurrent Neural Networks that are designed to deal with time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: How to make a proper Time Series Split ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine your `data` as 2D array structured as follows\n",
    "\n",
    "`data.shape = (n_timesteps, n_features)`\n",
    "\n",
    "`features` can be separated into 3 categories\n",
    "- targets\n",
    "- past-covariates\n",
    "- future-covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/time-series-covariates.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) First, create many **FOLDS** for your cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fold_1.shape = (n_timesteps_per_fold, n_features)`  as 2D arrays  \n",
    "`fold_2.shape = (n_timesteps_per_fold, n_features)`  as 2D arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always split your training set *chronologically before* your test set\n",
    "\n",
    "üëá e.g. 4-time cross validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/rnn-2.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create as many folds as needed to clearly test all type of past conditions \n",
    "(e.g crash markets periods üìâ, bull-run markets üìà, flat markets üò¥ etc...)\n",
    "\n",
    "It's very common to have **hundreds of folds** in Time Series forecasting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) in each FOLD, and for each train or test SET, split your time series into different SEQUENCES of (observations, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/rnn-1.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: create (`X_train`, `y_train`, `X_test`, `y_test`) containing all you need to train and test your model for this fold\n",
    "  \n",
    "- `X_train.shape = (n_samples, input_chunk_length, n_covariate_features)`\n",
    "- `y_train.shape = (n_samples, output_chunk_length, n_targets)`\n",
    "\n",
    "Notice that we now have 3D-arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üí° You can randomly sample or create them all sliding from left to right, with selected stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/sequence-length.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) üö® Beware of the **GAP** of length (horizon - 1) between each train & test sets in each fold to avoid data-leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='https://github.com/lewagon/data-images/blob/master/DL/rnn-2.png?raw=true' width = 400 ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Below is a zoom inside **ONE SINGLE FOLD**\n",
    "\n",
    "A gap of size `horizon - 1` is mandatory to reflect real situations:\n",
    "- Here the forecast horizon is `4` days\n",
    "- Let's say we want our train set to end by predicting day `10` based on days before `4, 5, 6`\n",
    "- In a real situation we would need to **wait** for day `10` to discover the true value of `y` on which to finalize training\n",
    "- Therefore, the test set can only start on day `10`, which is meant to predict `y_test = 10 + 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#2F8C41;font-size:20px'>horizon $h = 4$</span>\n",
    "\n",
    "$$ \\Large X^{t+\\color{green}4} = f(X^t, X^{t-1}, X^{t-2}) $$\n",
    "\n",
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/rnn-3.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Use [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) `TimeSeriesSplit(n_splits = ..., gap=...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Air Pollution Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/rnn-4.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data\n",
    "\n",
    "‚ùì **Question** ‚ùì We will load the data from the third and fourth exercise. Load the data, and keep only the following columns :  `['pm2.5', 'TEMP', 'DEWP', 'PRES', 'Ir', 'Is', 'Iws']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/deep_learning_datasets/air%20pollution.txt', index_col=[0])\n",
    "df = df[['pm2.5', 'TEMP', 'DEWP', 'PRES', 'Ir', 'Is', 'Iws']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì For the sake of simplicity, fill in the missing values with mean over the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, in classic settings, there is multiple independent sequences $X$, each with a corresponding $y$.\n",
    "However, if often happens that we don't have access to multiple sequences $X$, but to only one very long sequence as it is the case here. From that, experts usually split them into multiple sub-sequences.\n",
    "\n",
    "\n",
    "‚ùì **Question** ‚ùì Write a function that is able to get a subsequence $X$ and a corresponding $y$ which corresponds to the air pollution **5 days** after the last observation. The length of the subsequence should be an argument of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def subsample_sequence(df, length):\n",
    "    pass  # YOUR CODE HERE\n",
    "    return X, y\n",
    "\n",
    "subsample_sequence(df, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Given a list of integers, write a function that split the initial dataset as many times as there are integers in the list. The length of each sequence is the value of the integer in that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(df, length_of_observations):\n",
    "    X, y = [], []\n",
    "    pass  # YOUR CODE HERE\n",
    "    return X, y\n",
    "\n",
    "length_of_observations = np.random.randint(10, 15, 100)\n",
    "X, y = get_X_y(df, length_of_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì If you split into a train and test set _after_ creating the shorter sequences, you risk having same values in the train and test set, which corresponds to data leakage. Therefore, split your train and test set and then, get your training and test sequences - and the corresponding output.\n",
    "\n",
    "‚ùóÔ∏è Beware of the gap required between train and test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_observations = np.random.randint(10, 15, 100)\n",
    "X_train, y_train = get_X_y(df, length_of_observations)\n",
    "\n",
    "length_of_observations = np.random.randint(10, 15, 100)\n",
    "X_test, y_test = get_X_y(df, length_of_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sequence has a certain number of observations. But across sequences, this number of observations is not the same. Because the Neural Network is trained with *batches* of data, you must ensure that, once the sequences are concatenated, they can be represented as a tensor. This operation is called the padding\n",
    "\n",
    "‚ùì From the four sequences above, return a padded tensor (with the dedicated Keras function) and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "pass  # YOUR CODE HERE\n",
    "\n",
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "As you added data to your input just for computational reasons, your model has to know which one is useful or not. \n",
    "\n",
    "‚ùì Initialize a model and add a masking layer so that your model does not take the padded values into account. You have to tell which value you used for the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Compile your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Train your model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "plt.plot(history.history['val_mean_absolute_percentage_error'])\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
